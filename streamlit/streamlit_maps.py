

"""streamlit/streamlit_maps.py

Streamlit-–¥–µ—à–±–æ—Ä–¥ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ GPX-—Ç—Ä–µ–∫–æ–≤ –∏–∑ PostgreSQL.

–ß—Ç–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç:
- —Å–ø–∏—Å–æ–∫ —Ç—Ä–µ–∫–æ–≤ (tracks)
- –∫–∞—Ä—Ç—É —Å —Ç—Ä–µ–∫–æ–º (–ø–æ —Ç–æ—á–∫–∞–º –∏–∑ track_points)
- –±–∞–∑–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É (track_features)
- –∫–æ–Ω—Ç–µ–∫—Å—Ç (context_time_series): —á—Ç–æ —Ä—è–¥–æ–º (OSM/Overpass) –∏ –ø–æ–≥–æ–¥–∞ (Open-Meteo archive)

–ó–∞–ø—É—Å–∫ (–∏–∑ –∫–æ—Ä–Ω—è –ø—Ä–æ–µ–∫—Ç–∞):
    streamlit run streamlit/streamlit_maps.py

–í–∞–∂–Ω–æ –ø—Ä–æ —Å—Ö–µ–º—É:
- –°—Ö–µ–º–∞ –ë–î –±–µ—Ä—ë—Ç—Å—è –∏–∑ .env (PG_SCHEMA). –ú—ã –ù–ï —Ö–∞—Ä–¥–∫–æ–¥–∏–º public.
- –ù–∞ –∫–∞–∂–¥–æ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–∏ –≤—ã—Å—Ç–∞–≤–ª—è–µ–º `SET search_path`.

–ï—Å–ª–∏ —á–µ–≥–æ-—Ç–æ –Ω–µ—Ç (–Ω–∞–ø—Ä–∏–º–µ—Ä, context_time_series), –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –Ω–µ –ø–∞–¥–∞–µ—Ç,
–∞ –≤—ã–≤–æ–¥–∏—Ç –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ.
"""

from __future__ import annotations

# --- –í–ê–ñ–ù–û –¥–ª—è Streamlit ---
# Streamlit –∑–∞–ø—É—Å–∫–∞–µ—Ç —Ñ–∞–π–ª –∫–∞–∫ —Å–∫—Ä–∏–ø—Ç, –∏ –∏–Ω–æ–≥–¥–∞ –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –Ω–µ –ø–æ–ø–∞–¥–∞–µ—Ç –≤ PYTHONPATH.
# –ü–æ—ç—Ç–æ–º—É –∏–º–ø–æ—Ä—Ç `from src...` –º–æ–∂–µ—Ç –ø–∞–¥–∞—Ç—å —Å `ModuleNotFoundError: No module named 'src'`.
# –†–µ—à–µ–Ω–∏–µ: –¥–æ–±–∞–≤–∏—Ç—å –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –≤ sys.path.
import sys
from pathlib import Path

PROJECT_ROOT = Path(__file__).resolve().parents[1]  # .../mlbox_2
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

import json
import math

import numpy as np
from typing import Any, Dict, Optional, Tuple

import pandas as pd
import streamlit as st

# –ö–∞—Ä—Ç–∞: folium + streamlit-folium (–µ—Å–ª–∏ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø—Ä–æ—Å—Ç–æ –ø–æ–∫–∞–∂–µ–º —Ç–∞–±–ª–∏—Ü—ã)
try:
    import folium
    from branca.colormap import LinearColormap
    HAS_FOLIUM = True
except Exception:
    folium = None
    HAS_FOLIUM = False

try:
    from streamlit_folium import st_folium

    HAS_ST_FOLIUM = True
except Exception:
    st_folium = None
    HAS_ST_FOLIUM = False

from sqlalchemy import text

from src.common.db import DBConfig, get_connection, set_search_path, test_connection


# -----------------------------
# UI helpers
# -----------------------------

def _badge(label: str, value: Any) -> None:
    """–ú–∞–ª–µ–Ω—å–∫–∞—è –∫–∞—Ä—Ç–æ—á–∫–∞-–º–µ—Ç—Ä–∏–∫–∞."""
    st.metric(label, value)


# –ö—Ä–∞—Å–∏–≤–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —á–∏—Å–µ–ª –¥–ª—è UI (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã)
def _fmt_float(x: Any, ndigits: int = 2) -> str:
    """–ö—Ä–∞—Å–∏–≤–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —á–∏—Å–µ–ª –¥–ª—è UI."""
    try:
        if x is None or (isinstance(x, float) and (math.isnan(x))):
            return "‚Äî"
        return f"{float(x):.{ndigits}f}"
    except Exception:
        return "‚Äî"


def _safe_json(v: Any) -> Dict[str, Any]:
    """values –≤ –ë–î –º–æ–∂–µ—Ç –±—ã—Ç—å dict/json/—Å—Ç—Ä–æ–∫–∞. –ü—Ä–∏–≤–æ–¥–∏–º –∫ dict."""
    if v is None:
        return {}
    if isinstance(v, dict):
        return v
    if isinstance(v, str):
        try:
            return json.loads(v)
        except Exception:
            return {}
    return {}


# -----------------------------
# –ß–µ–ª–æ–≤–µ—á–µ—Å–∫–∞—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ OSM (nearby) –∏ –ø–æ–≥–æ–¥—ã
# -----------------------------

# –ü–µ—Ä–µ–≤–æ–¥ –∫–∞—Ç–µ–≥–æ—Ä–∏–π OSM (–∫–ª—é—á–∏ –≤–µ—Ä—Ö–Ω–µ–≥–æ —É—Ä–æ–≤–Ω—è)
TAG_RU = {
    "highway": "–î–æ—Ä–æ–≥–∏/–ø—É—Ç–∏",
    "landuse": "–¢–∏–ø –º–µ—Å—Ç–Ω–æ—Å—Ç–∏",
    "natural": "–ü—Ä–∏—Ä–æ–¥–∞",
    "waterway": "–í–æ–¥–∞ (—Ä–µ–∫–∏/–∫–∞–Ω–∞–ª—ã)",
    "building": "–ó–∞—Å—Ç—Ä–æ–π–∫–∞",
    "amenity": "–ò–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞",
    "leisure": "–î–æ—Å—É–≥/—Å–ø–æ—Ä—Ç",
}

# –ü–µ—Ä–µ–≤–æ–¥ —á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞—é—â–∏—Ö—Å—è –∑–Ω–∞—á–µ–Ω–∏–π. –ú–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä—è—Ç—å.
VALUE_RU = {
    # highway
    "footway": "–ø–µ—à–µ—Ö–æ–¥–Ω–∞—è –¥–æ—Ä–æ–∂–∫–∞/—Ç—Ä–æ—Ç—É–∞—Ä",
    "path": "—Ç—Ä–æ–ø–∞",
    "steps": "–ª–µ—Å—Ç–Ω–∏—Ü–∞",
    "residential": "–∂–∏–ª–∞—è —É–ª–∏—Ü–∞",
    "service": "—Å–ª—É–∂–µ–±–Ω—ã–π –ø—Ä–æ–µ–∑–¥",
    "primary": "–≥–ª–∞–≤–Ω–∞—è –¥–æ—Ä–æ–≥–∞",
    "secondary": "–≤—Ç–æ—Ä–æ—Å—Ç–µ–ø–µ–Ω–Ω–∞—è –¥–æ—Ä–æ–≥–∞",
    "tertiary": "–¥–æ—Ä–æ–≥–∞ –º–µ—Å—Ç–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è",
    "cycleway": "–≤–µ–ª–æ–¥–æ—Ä–æ–∂–∫–∞",
    "crossing": "–ø–µ—à–µ—Ö–æ–¥–Ω—ã–π –ø–µ—Ä–µ—Ö–æ–¥",
    "traffic_signals": "—Å–≤–µ—Ç–æ—Ñ–æ—Ä",
    "turning_circle": "—Ä–∞–∑–≤–æ—Ä–æ—Ç–Ω–∞—è –ø–ª–æ—â–∞–¥–∫–∞",
    "street_lamp": "—Ñ–æ–Ω–∞—Ä—å",

    # landuse
    "grass": "–≥–∞–∑–æ–Ω/—Ç—Ä–∞–≤–∞",
    "meadow": "–ª—É–≥",
    "industrial": "–ø—Ä–æ–º–∑–æ–Ω–∞",
    "construction": "—Å—Ç—Ä–æ–π–∫–∞",
    "retail": "—Ç–æ—Ä–≥–æ–≤–∞—è –∑–æ–Ω–∞",
    "allotments": "–¥–∞—á–∏/–æ–≥–æ—Ä–æ–¥—ã",

    # natural
    "wood": "–ª–µ—Å",
    "scrub": "–∫—É—Å—Ç–∞—Ä–Ω–∏–∫",
    "water": "–≤–æ–¥–æ—ë–º",
    "cliff": "–æ–±—Ä—ã–≤",
    "tree": "–¥–µ—Ä–µ–≤–æ",

    # building
    "yes": "–∑–¥–∞–Ω–∏–µ",
    "apartments": "–º–Ω–æ–≥–æ–∫–≤–∞—Ä—Ç–∏—Ä–Ω—ã–µ –¥–æ–º–∞",
    "detached": "—á–∞—Å—Ç–Ω—ã–µ –¥–æ–º–∞",
    "school": "—à–∫–æ–ª–∞",
    "shed": "—Ö–æ–∑–ø–æ—Å—Ç—Ä–æ–π–∫–∞/—Å–∞—Ä–∞–π",
    "hut": "–¥–æ–º–∏–∫/—Ö–∏–∂–∏–Ω–∞",

    # amenity
    "parking": "–ø–∞—Ä–∫–æ–≤–∫–∞",
    "bench": "–ª–∞–≤–æ—á–∫–∞",
    "pub": "–ø–∞–±/–±–∞—Ä",
    "post_box": "–ø–æ—á—Ç–æ–≤—ã–π —è—â–∏–∫",
    "post_office": "–ø–æ—á—Ç–∞",
    "bus_stop": "–æ—Å—Ç–∞–Ω–æ–≤–∫–∞",
    "bicycle_parking": "–≤–µ–ª–æ–ø–∞—Ä–∫–æ–≤–∫–∞",
    "waste_basket": "—É—Ä–Ω–∞",
    "parking_entrance": "–≤—ä–µ–∑–¥ –Ω–∞ –ø–∞—Ä–∫–æ–≤–∫—É",
}


def _ru_value(v: str) -> str:
    return VALUE_RU.get(v, v)


def _counts_to_rows(counts: dict) -> list:
    """counts —Ñ–æ—Ä–º–∞—Ç–∞ {"highway": [["residential", 16], ...], ...} -> –ø–ª–æ—Å–∫–∏–π —Å–ø–∏—Å–æ–∫."""
    rows = []
    if not isinstance(counts, dict):
        return rows
    for tag, arr in counts.items():
        if not isinstance(arr, list):
            continue
        for item in arr:
            if isinstance(item, (list, tuple)) and len(item) == 2:
                val, n = item[0], item[1]
                try:
                    n = int(n)
                except Exception:
                    continue
                rows.append(
                    {
                        "tag": str(tag),
                        "tag_ru": TAG_RU.get(str(tag), str(tag)),
                        "value": str(val),
                        "value_ru": _ru_value(str(val)),
                        "count": n,
                    }
                )
    return rows


def summarize_route_nearby(ctx_df: pd.DataFrame) -> pd.DataFrame:
    """–ê–≥—Ä–µ–≥–∏—Ä—É–µ–º nearby.counts –ø–æ –≤—Å–µ–º —Å—Ç—Ä–æ–∫–∞–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —Ç—Ä–µ–∫–∞."""
    if ctx_df is None or ctx_df.empty or "values" not in ctx_df.columns:
        return pd.DataFrame(columns=["tag_ru", "value_ru", "count", "tag", "value"])

    vals = ctx_df["values"].apply(_safe_json)
    all_rows = []
    for d in vals:
        nearby = d.get("nearby", {}) if isinstance(d, dict) else {}
        counts = nearby.get("counts", {}) if isinstance(nearby, dict) else {}
        all_rows.extend(_counts_to_rows(counts))

    if not all_rows:
        return pd.DataFrame(columns=["tag_ru", "value_ru", "count", "tag", "value"])

    df = pd.DataFrame(all_rows)
    df = df.groupby(["tag", "tag_ru", "value", "value_ru"], as_index=False)["count"].sum()
    df = df.sort_values("count", ascending=False).reset_index(drop=True)
    # –£–¥–æ–±–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ –∫–æ–ª–æ–Ω–æ–∫
    return df[["tag_ru", "value_ru", "count", "tag", "value"]]


def make_human_summary(agg_df: pd.DataFrame) -> str:
    """–ö–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç: —á—Ç–æ —á–∞—â–µ –≤—Å–µ–≥–æ –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è —Ä—è–¥–æ–º –ø–æ –º–∞—Ä—à—Ä—É—Ç—É."""
    if agg_df is None or agg_df.empty:
        return "–ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ –º–µ—Å—Ç–Ω–æ—Å—Ç–∏ –ø–æ–∫–∞ –Ω–µ —Å–æ–±—Ä–∞–Ω –∏–ª–∏ –ø—É—Å—Ç."

    top3 = agg_df.head(3)
    top_line = ", ".join(
        [f"{r['tag_ru']}: {r['value_ru']}√ó{int(r['count'])}" for _, r in top3.iterrows()]
    )

    # –°—Ç–∞–±–∏–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä –±–ª–æ–∫–æ–≤
    blocks = []
    for tag in ["highway", "natural", "waterway", "landuse", "building", "amenity"]:
        sub = agg_df[agg_df["tag"] == tag].head(3)
        if sub.empty:
            continue
        title = TAG_RU.get(tag, tag)
        items = ", ".join([f"{r['value_ru']} ({int(r['count'])})" for _, r in sub.iterrows()])
        blocks.append(f"- **{title}:** {items}")

    return (
        "### –ò—Ç–æ–≥ –ø–æ –º–∞—Ä—à—Ä—É—Ç—É (–∫–æ–Ω—Ç–µ–∫—Å—Ç —Ä—è–¥–æ–º)\n"
        f"- **–¢–û–ü-3:** {top_line}\n" + "\n".join(blocks)
    )


def weather_summary(ctx_df: pd.DataFrame) -> dict:
    """–°–≤–æ–¥–∫–∞ –ø–æ –ø–æ–≥–æ–¥–µ. –í–∞–∂–Ω–æ: —Å–µ–π—á–∞—Å –≤ –ë–î —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ temp_c (–µ—Å–ª–∏ –µ—Å—Ç—å –≤—Ä–µ–º—è)."""
    out = {
        "rows": 0,
        "ok": 0,
        "fail": 0,
        "no_time": 0,
        "temp_avg": None,
        "temp_min": None,
        "temp_max": None,
    }
    if ctx_df is None or ctx_df.empty or "values" not in ctx_df.columns:
        return out

    vals = ctx_df["values"].apply(_safe_json)
    out["rows"] = int(len(vals))

    temps = []
    for d in vals:
        w = d.get("weather", {}) if isinstance(d, dict) else {}
        if not isinstance(w, dict):
            continue
        ok = w.get("ok")
        if ok is True:
            out["ok"] += 1
        elif ok is False:
            out["fail"] += 1
            if w.get("reason") == "no_time":
                out["no_time"] += 1
        # temp
        t = w.get("temp_c")
        try:
            if t is not None:
                temps.append(float(t))
        except Exception:
            pass

    if temps:
        out["temp_avg"] = float(np.mean(temps))
        out["temp_min"] = float(np.min(temps))
        out["temp_max"] = float(np.max(temps))

    return out


def extract_weather_fields(values: Dict[str, Any]) -> Dict[str, Any]:
    """–î–æ—Å—Ç–∞—ë–º —É–¥–æ–±–Ω—ã–µ –ø–æ–ª—è –ø–æ–≥–æ–¥—ã –∏–∑ JSON values."""
    w = values.get("weather") if isinstance(values, dict) else None
    if not isinstance(w, dict):
        return {
            "weather_ok": None,
            "temp_c": None,
            "weather_reason": None,
            "hour_utc": None,
            "weather_source": None,
        }
    return {
        "weather_ok": w.get("ok"),
        "temp_c": w.get("temp_c"),
        "weather_reason": w.get("reason"),
        "hour_utc": w.get("hour_utc"),
        "weather_source": w.get("source"),
    }


def aggregate_nearby_counts(ctx_df: pd.DataFrame, top_n: int = 20, include_tech: bool = False) -> pd.DataFrame:
    """–¢–û–ü —Ä—è–¥–æ–º –ø–æ –º–∞—Ä—à—Ä—É—Ç—É, —Å —Ä—É—Å—Å–∫–∏–º–∏ –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏.

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–∞–±–ª–∏—Ü—É:
      - –ö–∞—Ç–µ–≥–æ—Ä–∏—è | –ó–Ω–∞—á–µ–Ω–∏–µ | –ö–æ–ª-–≤–æ

    –ï—Å–ª–∏ include_tech=True, –¥–æ–±–∞–≤–ª—è–µ—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø–æ–ª—è tag/value (—É–¥–æ–±–Ω–æ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏).
    """
    agg = summarize_route_nearby(ctx_df)
    if agg.empty:
        base_cols = ["–ö–∞—Ç–µ–≥–æ—Ä–∏—è", "–ó–Ω–∞—á–µ–Ω–∏–µ", "–ö–æ–ª-–≤–æ"]
        if include_tech:
            base_cols += ["tag", "value"]
        return pd.DataFrame(columns=base_cols)

    out = agg.head(top_n).copy()
    out = out.rename(columns={"tag_ru": "–ö–∞—Ç–µ–≥–æ—Ä–∏—è", "value_ru": "–ó–Ω–∞—á–µ–Ω–∏–µ", "count": "–ö–æ–ª-–≤–æ"})

    if include_tech:
        return out[["–ö–∞—Ç–µ–≥–æ—Ä–∏—è", "–ó–Ω–∞—á–µ–Ω–∏–µ", "–ö–æ–ª-–≤–æ", "tag", "value"]]
    return out[["–ö–∞—Ç–µ–≥–æ—Ä–∏—è", "–ó–Ω–∞—á–µ–Ω–∏–µ", "–ö–æ–ª-–≤–æ"]]


def build_context_summary(ctx_df: pd.DataFrame) -> Dict[str, Any]:
    """–ö–æ—Ä–æ—Ç–∫–∞—è —Å–≤–æ–¥–∫–∞ –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É (–ø–æ–≥–æ–¥–∞/–≤—Ä–µ–º—è)."""
    if ctx_df is None or ctx_df.empty:
        return {"rows": 0}

    vals = ctx_df["values"].apply(_safe_json)
    w = vals.apply(extract_weather_fields)
    w_df = pd.DataFrame(list(w))

    rows = int(len(ctx_df))
    ok_mask = w_df["weather_ok"] == True
    fail_mask = w_df["weather_ok"] == False
    no_time_mask = w_df["weather_reason"] == "no_time"

    temps = pd.to_numeric(w_df["temp_c"], errors="coerce")

    summary = {
        "rows": rows,
        "weather_ok": int(ok_mask.sum()),
        "weather_fail": int(fail_mask.sum()),
        "no_time": int(no_time_mask.sum()),
        "temp_avg": float(temps.mean()) if temps.notna().any() else None,
        "temp_min": float(temps.min()) if temps.notna().any() else None,
        "temp_max": float(temps.max()) if temps.notna().any() else None,
    }
    return summary


def _try_query_df(sql: str, params: Optional[dict] = None) -> Optional[pd.DataFrame]:
    """–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –∑–∞–ø—Ä–æ—Å: –µ—Å–ª–∏ —Ç–∞–±–ª–∏—Ü—ã/–∫–æ–ª–æ–Ω–∫–∏ –Ω–µ—Ç ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º None –∏ –ø–∏—à–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ."""
    try:
        with get_connection() as conn:
            set_search_path(conn)
            return pd.read_sql(text(sql), conn, params=params)
    except Exception as e:
        st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å. –í–æ–∑–º–æ–∂–Ω–æ, —Ç–∞–±–ª–∏—Ü—ã/–∫–æ–ª–æ–Ω–∫–∏ –Ω–µ—Ç –∏–ª–∏ –Ω–µ—Ç –ø—Ä–∞–≤. –û—à–∏–±–∫–∞: {e}")
        return None


# -----------------------------
# Data access
# -----------------------------

@st.cache_data(ttl=30)
def load_tracks() -> pd.DataFrame:
    """–°–ø–∏—Å–æ–∫ —Ç—Ä–µ–∫–æ–≤."""
    sql = """
    SELECT
        track_id,
        source_id,
        track_name,
        start_time,
        end_time,
        segment_count,
        point_count,
        min_lat, min_lon, max_lat, max_lon
    FROM tracks
    ORDER BY track_id;
    """
    df = _try_query_df(sql)
    return df if df is not None else pd.DataFrame()


@st.cache_data(ttl=30)
def load_track_features(track_id: int) -> Optional[pd.DataFrame]:
    sql = """
    SELECT *
    FROM track_features
    WHERE track_id = :track_id
    LIMIT 1;
    """
    return _try_query_df(sql, {"track_id": track_id})


@st.cache_data(ttl=30)
def load_track_points(track_id: int) -> pd.DataFrame:
    """–¢–æ—á–∫–∏ —Ç—Ä–µ–∫–∞. –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ segment_index, seq."""
    sql = """
    SELECT track_id, segment_index, seq, lat, lon, ele, time, speed
    FROM track_points
    WHERE track_id = :track_id
    ORDER BY segment_index, seq;
    """
    df = _try_query_df(sql, {"track_id": track_id})
    return df if df is not None else pd.DataFrame()


@st.cache_data(ttl=30)
def load_context_for_source(source_id: int) -> pd.DataFrame:
    """–ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è source_id (–≤ context_time_series –ª–µ–∂–∏—Ç source_id, –∞ –Ω–µ track_id)."""
    sql = """
    SELECT context_id, source_id, time, lat, lon, values
    FROM context_time_series
    WHERE source_id = :source_id
    ORDER BY time NULLS LAST, context_id;
    """
    df = _try_query_df(sql, {"source_id": source_id})
    return df if df is not None else pd.DataFrame()


# -----------------------------
# Map building
# -----------------------------


def _center_from_bbox(row: pd.Series) -> Tuple[float, float]:
    """–¶–µ–Ω—Ç—Ä –∫–∞—Ä—Ç—ã: –∏–∑ bbox, –∏–Ω–∞—á–µ –∏–∑ –ø–µ—Ä–≤–æ–π —Ç–æ—á–∫–∏."""
    try:
        lat = (float(row["min_lat"]) + float(row["max_lat"])) / 2.0
        lon = (float(row["min_lon"]) + float(row["max_lon"])) / 2.0
        if pd.isna(lat) or pd.isna(lon):
            raise ValueError("bbox is NaN")
        return lat, lon
    except Exception:
        return 0.0, 0.0


def build_map(
    track_row: pd.Series,
    points_df: pd.DataFrame,
    ctx_df: Optional[pd.DataFrame],
    sample_points_step: int,
    sample_ctx_step: int,
) -> "folium.Map":
    """–°–æ–±–∏—Ä–∞–µ–º folium –∫–∞—Ä—Ç—É —Å —Ç—Ä–µ–∫–æ–º –∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º."""

    # –¶–µ–Ω—Ç—Ä: bbox —Ç—Ä–µ–∫–∞, –∏–Ω–∞—á–µ –ø–æ –ø–µ—Ä–≤–æ–π —Ç–æ—á–∫–µ
    center = _center_from_bbox(track_row)
    if center == (0.0, 0.0) and not points_df.empty:
        center = (float(points_df.iloc[0]["lat"]), float(points_df.iloc[0]["lon"]))

    m = folium.Map(location=center, zoom_start=12, control_scale=True, tiles=None)

    # –ë–∞–∑–æ–≤—ã–µ —Ç–∞–π–ª—ã (OSM). –≠—Ç–æ –∏ –µ—Å—Ç—å "–ø–æ–¥—Ç—è–Ω—É—Ç—å –∫–∞—Ä—Ç—É –∏–∑ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤".
    folium.TileLayer(
        tiles="https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png",
        attr="¬© OpenStreetMap contributors",
        name="OpenStreetMap",
        overlay=False,
        control=True,
    ).add_to(m)

    # –î–æ–ø. —Å–ª–æ–π: —Ä–µ–ª—å–µ—Ñ/—Ç–æ–ø–æ (–º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –≤ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —Å–µ—Ç—è—Ö, –Ω–æ –æ–±—ã—á–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç)
    folium.TileLayer(
        tiles="https://{s}.tile.opentopomap.org/{z}/{x}/{y}.png",
        attr="¬© OpenTopoMap (CC-BY-SA)",
        name="OpenTopoMap",
        overlay=False,
        control=True,
        show=False,
    ).add_to(m)

    # –õ–∏–Ω–∏—è —Ç—Ä–µ–∫–∞
    if not points_df.empty:
        # –ß—Ç–æ–±—ã –∫–∞—Ä—Ç–∞ –Ω–µ —Ç–æ—Ä–º–æ–∑–∏–ª–∞, —Ä–∏—Å—É–µ–º –ø–æ–ª–∏–ª–∏–Ω–∏—é –ø–æ —Å—ç–º–ø–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–º —Ç–æ—á–∫–∞–º
        pts = points_df.iloc[:: max(1, sample_points_step)][["lat", "lon"]].dropna()
        latlon = pts.values.tolist()
        if len(latlon) >= 2:
            folium.PolyLine(latlon, weight=4, opacity=0.9, tooltip="–¢—Ä–µ–∫").add_to(m)

        # –ú–∞—Ä–∫–µ—Ä—ã —Å—Ç–∞—Ä—Ç/—Ñ–∏–Ω–∏—à
        start = points_df.iloc[0]
        end = points_df.iloc[-1]
        folium.Marker(
            [float(start["lat"]), float(start["lon"])],
            tooltip="–°—Ç–∞—Ä—Ç",
            icon=folium.Icon(color="green", icon="play"),
        ).add_to(m)
        folium.Marker(
            [float(end["lat"]), float(end["lon"])],
            tooltip="–§–∏–Ω–∏—à",
            icon=folium.Icon(color="red", icon="stop"),
        ).add_to(m)

    # –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ —Ç–æ—á–∫–∏: –ø–æ–∫–∞–∑—ã–≤–∞–µ–º nearby –∏ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É (—Ü–≤–µ—Ç–æ–º)
    if ctx_df is not None and not ctx_df.empty:
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∏–º –¥–∏–∞–ø–∞–∑–æ–Ω —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä –¥–ª—è —Ü–≤–µ—Ç–æ–≤–æ–π —à–∫–∞–ª—ã
        vals_all = ctx_df["values"].apply(_safe_json)
        temps_all = vals_all.apply(lambda d: d.get("weather", {}).get("temp_c") if isinstance(d, dict) else None)
        temps_num = pd.to_numeric(pd.Series(list(temps_all)), errors="coerce")

        tmin = float(temps_num.min()) if temps_num.notna().any() else None
        tmax = float(temps_num.max()) if temps_num.notna().any() else None

        colormap = None
        if tmin is not None and tmax is not None and tmin != tmax:
            colormap = LinearColormap(["blue", "green", "orange", "red"], vmin=tmin, vmax=tmax)
            colormap.caption = "–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ (¬∞C)"
            colormap.add_to(m)

        grp_ctx = folium.FeatureGroup(name="–ö–æ–Ω—Ç–µ–∫—Å—Ç (nearby/weather)", show=True)

        sampled = ctx_df.iloc[:: max(1, sample_ctx_step)].copy()
        for _, r in sampled.iterrows():
            lat = float(r["lat"])
            lon = float(r["lon"])
            vals = _safe_json(r.get("values"))

            weather = vals.get("weather", {}) if isinstance(vals, dict) else {}
            w_ok = weather.get("ok") if isinstance(weather, dict) else None
            temp = weather.get("temp_c") if isinstance(weather, dict) else None
            w_reason = weather.get("reason") if isinstance(weather, dict) else None

            nearby = vals.get("nearby", {}) if isinstance(vals, dict) else {}
            counts = (nearby.get("counts") or {}) if isinstance(nearby, dict) else {}

            # –¢–æ–ø –∫–∞—Ç–µ–≥–æ—Ä–∏–π –ø–æ —á–∞—Å—Ç–æ—Ç–µ (–æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–æ)
            top_lines = []
            try:
                for k, arr in list(counts.items())[:6]:
                    if isinstance(arr, list) and arr:
                        v0 = arr[0]
                        if isinstance(v0, (list, tuple)) and len(v0) == 2:
                            top_lines.append(f"{k}: {v0[0]}√ó{v0[1]}")
                        else:
                            top_lines.append(f"{k}: {len(arr)}")
                    else:
                        top_lines.append(f"{k}: 0")
            except Exception:
                top_lines = []

            t = r.get("time")
            t_str = str(t) if pd.notna(t) else "(no_time)"

            popup_html = """
            <div style="font-size: 12px;">
              <b>–ö–æ–Ω—Ç–µ–∫—Å—Ç —Ç–æ—á–∫–∏</b><br/>
              <b>time:</b> {t}<br/>
              <b>temp:</b> {temp}<br/>
              <b>weather_ok:</b> {wok}<br/>
              <b>weather_reason:</b> {wreason}<br/>
              <hr style="margin:6px 0;"/>
              <b>nearby (top):</b><br/>
              {tops}
            </div>
            """.format(
                t=t_str,
                temp=(f"{temp} ¬∞C" if temp is not None else "‚Äî"),
                wok=("true" if w_ok else "false" if w_ok is not None else "‚Äî"),
                wreason=(w_reason or "‚Äî"),
                tops=("<br/>".join(top_lines) if top_lines else "‚Äî"),
            )

            # –¶–≤–µ—Ç —Ç–æ—á–∫–∏: –µ—Å–ª–∏ –µ—Å—Ç—å —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ ‚Äî –ø–æ —à–∫–∞–ª–µ, –∏–Ω–∞—á–µ –ø–æ —Å—Ç–∞—Ç—É—Å—É –ø–æ–≥–æ–¥—ã
            if colormap is not None and temp is not None:
                try:
                    color = colormap(float(temp))
                except Exception:
                    color = "blue"
            else:
                # fallback
                if w_ok is True:
                    color = "blue"
                elif w_reason == "no_time":
                    color = "gray"
                elif w_ok is False:
                    color = "orange"
                else:
                    color = "blue"

            folium.CircleMarker(
                location=[lat, lon],
                radius=6,
                color=color,
                fill=True,
                fill_opacity=0.75,
                popup=folium.Popup(popup_html, max_width=360),
            ).add_to(grp_ctx)

        grp_ctx.add_to(m)

    folium.LayerControl(collapsed=True).add_to(m)
    return m


# -----------------------------
# App
# -----------------------------


def main() -> None:
    st.set_page_config(page_title="GPX –∫–∞—Ä—Ç—ã", layout="wide")
    st.title("üó∫Ô∏è GPX-—Ç—Ä–µ–∫–∏: –∫–∞—Ä—Ç–∞, —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
    try:
        test_connection(verbose=True)
        cfg = DBConfig.from_env()
        st.caption(f"–°—Ö–µ–º–∞: `{cfg.schema}` (–∏–∑ .env PG_SCHEMA)")
    except Exception as e:
        st.error(f"–ù–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î. –ü—Ä–æ–≤–µ—Ä—å .env –∏ —Å–µ—Ä–≤–µ—Ä PostgreSQL. –û—à–∏–±–∫–∞: {e}")
        st.stop()

    # –°–∞–π–¥–±–∞—Ä: –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    st.sidebar.header("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è")
    sample_points_step = st.sidebar.slider("–¢–æ—á–∫–∏ —Ç—Ä–µ–∫–∞ –Ω–∞ –∫–∞—Ä—Ç–µ: –∫–∞–∂–¥–∞—è N-—è", 1, 1000, 10, 1)
    sample_ctx_step = st.sidebar.slider("–¢–æ—á–∫–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –Ω–∞ –∫–∞—Ä—Ç–µ: –∫–∞–∂–¥–∞—è N-—è", 1, 1000, 1, 1)
    show_tech_cols = st.sidebar.checkbox("–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø–æ–ª—è (tag/value)", value=False)

    tracks = load_tracks()
    if tracks.empty:
        st.warning("–¢–∞–±–ª–∏—Ü–∞ tracks –ø—É—Å—Ç–∞ –∏–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞.")
        st.stop()

    # –í—ã–±–æ—Ä —Ç—Ä–µ–∫–∞
    tracks_display = tracks.copy()
    tracks_display["label"] = tracks_display.apply(
        lambda r: f"{int(r['track_id'])} | {str(r['track_name'])}", axis=1
    )

    selected_label = st.sidebar.selectbox("–í—ã–±–µ—Ä–∏ —Ç—Ä–µ–∫", tracks_display["label"].tolist())
    selected_row = tracks_display.loc[tracks_display["label"] == selected_label].iloc[0]
    track_id = int(selected_row["track_id"])
    source_id = int(selected_row["source_id"])

    # –ì—Ä—É–∑–∏–º –¥–∞–Ω–Ω—ã–µ
    pts = load_track_points(track_id)
    feats = load_track_features(track_id)

    # –ö–æ–Ω—Ç–µ–∫—Å—Ç –º–æ–∂–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å
    ctx = load_context_for_source(source_id)

    # –í–µ—Ä—Ö–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏
    c1, c2, c3, c4, c5 = st.columns(5)
    with c1:
        _badge("ID —Ç—Ä–µ–∫–∞", track_id)
    with c2:
        _badge("–¢–æ—á–µ–∫ —Ç—Ä–µ–∫–∞", int(selected_row.get("point_count", 0) or 0))
    with c3:
        _badge("–¢–æ—á–µ–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞", 0 if ctx is None else int(len(ctx)))
    with c4:
        _badge("–ù–∞—á–∞–ª–æ", str(selected_row.get("start_time")))
    with c5:
        _badge("–ö–æ–Ω–µ—Ü", str(selected_row.get("end_time")))

    left, right = st.columns([2, 1])

    # –ö–∞—Ä—Ç–∞
    with left:
        st.subheader("–ö–∞—Ä—Ç–∞")
        if not (HAS_FOLIUM and HAS_ST_FOLIUM):
            st.warning(
                "–î–ª—è –∫–∞—Ä—Ç—ã –Ω—É–∂–µ–Ω `folium` –∏ `streamlit-folium`. "
                "–£—Å—Ç–∞–Ω–æ–≤–∏: pip install folium streamlit-folium"
            )
        else:
            m = build_map(
                track_row=selected_row,
                points_df=pts,
                ctx_df=ctx,
                sample_points_step=sample_points_step,
                sample_ctx_step=sample_ctx_step,
            )
            st_folium(m, height=650, width=None)

    # –ü—Ä–∞–≤–∞—è –ø–∞–Ω–µ–ª—å: —Ñ–∏—á–∏ + –∫–æ–Ω—Ç–µ–∫—Å—Ç summary
    with right:
        st.subheader("–§–∏—á–∏ —Ç—Ä–µ–∫–∞")
        if feats is None or feats.empty:
            st.info("track_features –¥–ª—è —ç—Ç–æ–≥–æ —Ç—Ä–µ–∫–∞ –Ω–µ—Ç (–∏–ª–∏ —Ç–∞–±–ª–∏—Ü–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞).")
        else:
            r = feats.iloc[0]
            show_cols = [
                ("distance_m", "–î–∏—Å—Ç–∞–Ω—Ü–∏—è", "–º"),
                ("duration_s", "–î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å", "—Å"),
                ("avg_speed_mps", "–°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å", "–º/—Å"),
                ("max_speed_mps", "–ú–∞–∫—Å. —Å–∫–æ—Ä–æ—Å—Ç—å", "–º/—Å"),
                ("elev_min_m", "–ú–∏–Ω. –≤—ã—Å–æ—Ç–∞", "–º"),
                ("elev_max_m", "–ú–∞–∫—Å. –≤—ã—Å–æ—Ç–∞", "–º"),
                ("elev_gain_m", "–ù–∞–±–æ—Ä –≤—ã—Å–æ—Ç—ã", "–º"),
                ("elev_loss_m", "–°–±—Ä–æ—Å –≤—ã—Å–æ—Ç—ã", "–º"),
                ("stop_time_s", "–í—Ä–µ–º—è –æ—Å—Ç–∞–Ω–æ–≤–æ–∫", "—Å"),
                ("stop_ratio", "–î–æ–ª—è –æ—Å—Ç–∞–Ω–æ–≤–æ–∫", ""),
                ("point_density_per_km", "–ü–ª–æ—Ç–Ω–æ—Å—Ç—å —Ç–æ—á–µ–∫", "—Ç–æ—á–µ–∫/–∫–º"),
            ]
            data_ru = {}
            for key, title, unit in show_cols:
                if key in feats.columns:
                    val = r.get(key)
                    # stop_ratio –∫—Ä–∞—Å–∏–≤–µ–µ –∫–∞–∫ %
                    if key == "stop_ratio" and val is not None:
                        try:
                            data_ru[f"{title}"] = f"{float(val) * 100:.1f}%"
                            continue
                        except Exception:
                            pass
                    # –æ—Å—Ç–∞–ª—å–Ω—ã–µ ‚Äî —á–∏—Å–ª–∞
                    if isinstance(val, (int, float)):
                        data_ru[f"{title}{(' (' + unit + ')') if unit else ''}"] = float(val)
                    else:
                        data_ru[f"{title}{(' (' + unit + ')') if unit else ''}"] = val
            st.json(data_ru, expanded=False)

        st.subheader("–ö–æ–Ω—Ç–µ–∫—Å—Ç –º–∞—Ä—à—Ä—É—Ç–∞ (–º–µ—Å—Ç–Ω–æ—Å—Ç—å –∏ –ø–æ–≥–æ–¥–∞)")
        st.caption(
            "–°–º—ã—Å–ª –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: –Ω–µ –ø—Ä–æ—Å—Ç–æ –Ω–∞—Ä–∏—Å–æ–≤–∞—Ç—å –ª–∏–Ω–∏—é –ø–æ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º, "
            "–∞ –æ–±—ä—è—Å–Ω–∏—Ç—å *–ø–æ –∫–∞–∫–æ–π –º–µ—Å—Ç–Ω–æ—Å—Ç–∏* –ø—Ä–æ—Ö–æ–¥–∏–ª –º–∞—Ä—à—Ä—É—Ç (–¥–æ—Ä–æ–≥–∏/—Ç—Ä–æ–ø—ã/–ª–µ—Å/–≤–æ–¥–∞/–∑–∞—Å—Ç—Ä–æ–π–∫–∞) "
            "–∏ –∫–∞–∫–∞—è –±—ã–ª–∞ *–ø–æ–≥–æ–¥–∞* –≤ –º–æ–º–µ–Ω—Ç –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è. "
            "–≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å —Ç—Ä–µ–∫–∏ –º–µ–∂–¥—É —Å–æ–±–æ–π –∏ –¥–µ–ª–∞—Ç—å –≤—ã–≤–æ–¥—ã."
        )

        if ctx is None or ctx.empty:
            st.info(
                "–ö–æ–Ω—Ç–µ–∫—Å—Ç–∞ –Ω–µ—Ç (context_time_series –ø—É—Å—Ç –∏–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω). "
                "–°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏: python -m src.enrich_context"
            )
        else:
            # 1) –°–≤–æ–¥–∫–∞ –ø–æ –ø–æ–≥–æ–¥–µ (—á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏)
            ws = weather_summary(ctx)
            m1, m2, m3, m4 = st.columns(4)
            with m1:
                st.metric("–°—Ç—Ä–æ–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞", ws.get("rows", 0))
            with m2:
                st.metric("–ü–æ–≥–æ–¥–∞ –ø–æ–ª—É—á–µ–Ω–∞", ws.get("ok", 0))
            with m3:
                st.metric("–ü–æ–≥–æ–¥–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞", ws.get("fail", 0))
            with m4:
                st.metric("–ù–µ—Ç –≤—Ä–µ–º–µ–Ω–∏ –≤ GPX", ws.get("no_time", 0))

            if ws.get("temp_avg") is not None:
                st.markdown("**–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –ø–æ –¥–æ—Å—Ç—É–ø–Ω—ã–º —Ç–æ—á–∫–∞–º (¬∞C):**")
                t1, t2, t3 = st.columns(3)
                with t1:
                    st.metric("–°—Ä–µ–¥–Ω—è—è", _fmt_float(ws.get("temp_avg"), 1))
                with t2:
                    st.metric("–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è", _fmt_float(ws.get("temp_min"), 1))
                with t3:
                    st.metric("–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è", _fmt_float(ws.get("temp_max"), 1))
            else:
                st.info(
                    "–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã –Ω–µ—Ç: —á–∞—â–µ –≤—Å–µ–≥–æ —ç—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –≤ GPX –Ω–µ—Ç –≤—Ä–µ–º–µ–Ω–∏ (time), "
                    "–∏–ª–∏ –ø–æ–≥–æ–¥–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω."
                )

            st.divider()

            # 2) –ò—Ç–æ–≥ –ø–æ –º–µ—Å—Ç–Ω–æ—Å—Ç–∏ (–≥–ª–∞–≤–Ω–∞—è —á–∞—Å—Ç—å –∑–∞–¥–∞–Ω–∏—è!)
            agg_ru = summarize_route_nearby(ctx)
            st.markdown(make_human_summary(agg_ru))

            st.caption("–¢–û–ü-20 –æ–±—ä–µ–∫—Ç–æ–≤ —Ä—è–¥–æ–º —Å –º–∞—Ä—à—Ä—É—Ç–æ–º (—Å–≤–æ–¥–∫–∞ –ø–æ —Ç–µ–≥–∞–º OSM; —É–¥–æ–±–Ω–æ –≤—Å—Ç–∞–≤–ª—è—Ç—å –≤ –æ—Ç—á—ë—Ç)")
            top_nearby = aggregate_nearby_counts(ctx, top_n=20, include_tech=show_tech_cols)
            if top_nearby.empty:
                st.info(
                    "nearby.counts –ø—É—Å—Ç ‚Äî –≤–æ–∑–º–æ–∂–Ω–æ, Overpass –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª (429/504) "
                    "–∏–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –µ—â—ë –Ω–µ —É—Å–ø–µ–ª —Å–æ–±—Ä–∞—Ç—å—Å—è. "
                    "–†–µ—à–µ–Ω–∏–µ: –ø–æ–ø—Ä–æ–±—É–π —É–≤–µ–ª–∏—á–∏—Ç—å –∑–∞–¥–µ—Ä–∂–∫—É --sleep-s (–Ω–∞–ø—Ä–∏–º–µ—Ä, 1‚Äì2 —Å–µ–∫) "
                    "–∏/–∏–ª–∏ —É–º–µ–Ω—å—à–∏—Ç—å —á–∞—Å—Ç–æ—Ç—É —Ç–æ—á–µ–∫ (--point-step).")
            else:
                st.dataframe(top_nearby, use_container_width=True, height=320)

                # –ù–µ–±–æ–ª—å—à–æ–π –≥—Ä–∞—Ñ–∏–∫: —Ç–æ–ª—å–∫–æ —á–µ–ª–æ–≤–µ–∫–æ-–ø–æ–Ω—è—Ç–Ω—ã–µ –ø–æ–¥–ø–∏—Å–∏
                chart_df = top_nearby.copy()
                chart_df["label"] = chart_df.apply(lambda r: f"{r['–ö–∞—Ç–µ–≥–æ—Ä–∏—è']}: {r['–ó–Ω–∞—á–µ–Ω–∏–µ']}", axis=1)
                chart_df = chart_df.set_index("label")[["–ö–æ–ª-–≤–æ"]]
                st.bar_chart(chart_df)

            st.divider()

            # 3) –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)
            vals = ctx["values"].apply(_safe_json)
            weather_rows = pd.DataFrame(list(vals.apply(extract_weather_fields)))
            temp_series = pd.to_numeric(weather_rows["temp_c"], errors="coerce")
            if temp_series.notna().sum() >= 2:
                st.caption("–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –ø–æ —Ç–æ—á–∫–∞–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞")
                tdf = pd.DataFrame({"time": ctx["time"], "temp_c": temp_series}).dropna()
                tdf = tdf.sort_values("time")
                st.line_chart(tdf.set_index("time")["temp_c"])

            st.caption("–ü–æ—Å–ª–µ–¥–Ω–∏–µ 5 —Å—Ç—Ä–æ–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è / –¥–µ–±–∞–≥–∞)")
            view = ctx.tail(5).copy()
            view["values"] = view["values"].apply(_safe_json)
            st.dataframe(view[["context_id", "time", "lat", "lon", "values"]], use_container_width=True, height=260)

    # –ù–∏–∂–µ: —Ç–æ—á–∫–∏/—Ç–∞–±–ª–∏—Ü—ã
    st.divider()
    st.subheader("–î–∞–Ω–Ω—ã–µ")
    tabs = st.tabs(["–¢—Ä–µ–∫–∏", "–¢–æ—á–∫–∏ —Ç—Ä–µ–∫–∞", "–ö–æ–Ω—Ç–µ–∫—Å—Ç (OSM/–ø–æ–≥–æ–¥–∞)"])

    with tabs[0]:
        st.dataframe(tracks.drop(columns=["label"], errors="ignore"), use_container_width=True, height=320)

    with tabs[1]:
        if pts.empty:
            st.info("–¢–æ—á–µ–∫ –Ω–µ—Ç")
        else:
            st.caption("–ü–µ—Ä–≤—ã–µ 200 —Ç–æ—á–µ–∫ (–¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è)")
            st.dataframe(pts.head(200), use_container_width=True, height=320)

    with tabs[2]:
        if ctx is None or ctx.empty:
            st.info("–ö–æ–Ω—Ç–µ–∫—Å—Ç–∞ –Ω–µ—Ç")
        else:
            st.caption("–ü–µ—Ä–≤—ã–µ 200 —Å—Ç—Ä–æ–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è)")
            cview = ctx.copy()
            cview["values"] = cview["values"].apply(_safe_json)
            st.dataframe(cview.head(200), use_container_width=True, height=320)


if __name__ == "__main__":
    main()